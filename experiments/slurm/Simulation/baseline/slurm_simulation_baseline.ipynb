{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd17711-8211-4a6c-a143-bfd23ca70ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import os \n",
    "import sys\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client\n",
    "from pathlib import Path\n",
    "\n",
    "import do_simulation_baseline as file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc39ade-9681-449d-bda2-588ad33554c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args setup\n",
    "ntrial = 50\n",
    "n = 500\n",
    "n_int = 100\n",
    "niter = 1000\n",
    "front_door = True\n",
    "minimise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af96fcf-2028-4154-af52-ca94c6de9876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/ghome/live/danceh/.local/mambaforge/envs/causalgp/lib/python3.12/site-packages/distributed/node.py:187: UserWarning: Port 11111 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 37881 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cluster creation\n",
    "cluster = SLURMCluster(\n",
    "    n_workers=0,\n",
    "    memory=\"32GB\",\n",
    "    processes=1,\n",
    "    cores=1,\n",
    "    scheduler_options={\n",
    "        \"dashboard_address\": \":11111\",\n",
    "        \"allowed_failures\": 10\n",
    "    },\n",
    "    job_cpu=1,\n",
    "    walltime=\"3:0:0\",\n",
    "    \n",
    "    job_extra_directives = [\"-p medium,fast,cpu\"],\n",
    ")\n",
    "cluster.adapt(minimum=0, maximum=200)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512e36b3-47b6-4200-bb66-ce2050429a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submitting jobs\n",
    "futures = []\n",
    "for seed in range(ntrial):\n",
    "        f = client.submit(file.main,\n",
    "                              seed,\n",
    "                              n,n_int,\n",
    "                              niter = niter,\n",
    "                              front_door = front_door,\n",
    "                              minimise = minimise\n",
    "                             )\n",
    "        futures += [f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5378f77d-7908-4cd5-990a-9e0f1888000f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: pending, key: main-3d5c36680fb13c0f45a1d8bae99fcac5>,\n",
       " <Future: pending, key: main-4f528d85bbf46ea059898c4ba90aa41c>,\n",
       " <Future: pending, key: main-64dee34a5a3ffeb5bd8a268bc2700922>,\n",
       " <Future: pending, key: main-78f4d652ba700f822d99a480d933b8f6>,\n",
       " <Future: pending, key: main-1350a527f50fb382bd99d87e04f26f86>,\n",
       " <Future: pending, key: main-ea3976cff009c1f8dfe0289c6ccee3f6>,\n",
       " <Future: pending, key: main-2b81570ac0e8fe8edbe955f4aa45b304>,\n",
       " <Future: pending, key: main-9e4847b12dc0a64bc748b7c30d6f87d9>,\n",
       " <Future: pending, key: main-ef5b15474f9a5e448a4179b37f9893d5>,\n",
       " <Future: pending, key: main-2752958b0b65e305e4f50672840f8c55>,\n",
       " <Future: pending, key: main-aa15f009a71e4c042db815be0ce08a1b>,\n",
       " <Future: pending, key: main-b7c3b6177f04f612e085182befc7f3b8>,\n",
       " <Future: pending, key: main-dd79a32c2b6ed02304b692756ac2c47c>,\n",
       " <Future: pending, key: main-fa9970db8eb14610cbc6ee3c959ea743>,\n",
       " <Future: pending, key: main-b93b15e24e783fdabb4ac8ae830a29bf>,\n",
       " <Future: pending, key: main-b925646c837bc899ed646910802f4116>,\n",
       " <Future: pending, key: main-4abdc4db2e63362f938d559976cfc55d>,\n",
       " <Future: pending, key: main-0fd50548b106afe281cb31ef5fb22a03>,\n",
       " <Future: pending, key: main-6082e4be42de29da814dbd7d45bb3909>,\n",
       " <Future: pending, key: main-146089c41875a2bf7f77afcadfe38284>,\n",
       " <Future: pending, key: main-30c831997659963b85da74525d648347>,\n",
       " <Future: pending, key: main-4e063ac36453df4d333105f4ae1bfc4e>,\n",
       " <Future: pending, key: main-b46bc4942c441b7e5693ef1fc1e97462>,\n",
       " <Future: pending, key: main-669e58d06208dde3fe11399574a6d13f>,\n",
       " <Future: pending, key: main-68a51f89007fc0ab6c3f6894d2e24e44>,\n",
       " <Future: pending, key: main-6e8eae2c4d39c03c40d313b7d4862728>,\n",
       " <Future: pending, key: main-7a014b174f0481b5bac0bcbe7c60f654>,\n",
       " <Future: pending, key: main-9c10bb02fed9a4e3620aca28b480c094>,\n",
       " <Future: pending, key: main-fdd608092381419571058bad8fa1e8cd>,\n",
       " <Future: pending, key: main-b9724195734547b0e19e94087d4cf3f5>,\n",
       " <Future: pending, key: main-36dd6e81f401dee273c60539f40f73ab>,\n",
       " <Future: pending, key: main-8660acb1f0b54a42a0fd362251c28dbd>,\n",
       " <Future: pending, key: main-3805b1ac1c7111f1963d6ee48c270813>,\n",
       " <Future: pending, key: main-048df585c40b4e95cd71943ba4905ef2>,\n",
       " <Future: pending, key: main-48c8fa6fda866c87c036531d68cfa446>,\n",
       " <Future: pending, key: main-8971c2951049aee33ea5e79ab5cc5320>,\n",
       " <Future: pending, key: main-721366c417f3197ff3d2e9d304b6cf69>,\n",
       " <Future: pending, key: main-5152d7c4110dd056e44a0aa4f0f93793>,\n",
       " <Future: pending, key: main-e7f7fa59c340cbdbd50a765cafcc1c64>,\n",
       " <Future: pending, key: main-17f9a8ff8b009f19598617853d9d5c0c>,\n",
       " <Future: pending, key: main-feb4ae854ea4363f04eb045c0f83ef1b>,\n",
       " <Future: pending, key: main-2772aadd14568dc09a4edd56bca2d06f>,\n",
       " <Future: pending, key: main-588c5cb8890c99af8ca137e47ff1d357>,\n",
       " <Future: pending, key: main-6537599726ce0d387b638528ba2e8590>,\n",
       " <Future: pending, key: main-992f9c9240bcda6a143738587fb7e06a>,\n",
       " <Future: pending, key: main-aca62d036e6a87c128117d4c0fff001f>,\n",
       " <Future: pending, key: main-a2c82c2904e40d043553269964ba8bd6>,\n",
       " <Future: pending, key: main-ad2054f47b1cf9e27cc92676d3d5dd5c>,\n",
       " <Future: pending, key: main-707cd4501db90ee080f58a65f19274f8>,\n",
       " <Future: pending, key: main-4d2740da4299653324a36aa55c9a1faa>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99fb39c7-f5c1-4d44-92df-b1a94309a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting results\n",
    "results = client.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa104ec-b8bc-406e-a690-ccc6a03a8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing client\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7eccd97-9915-4715-ae3c-23d065c72172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results\n",
    "torch.save(obj = results,\n",
    "           f = \"simulation_baseline_ntrial={0}_n={1}_frontdoor={2}_minimise={3}.pt\".format(ntrial,\n",
    "                                                                                             n,\n",
    "                                                                                             front_door,\n",
    "                                                                                             minimise)\n",
    "          )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
