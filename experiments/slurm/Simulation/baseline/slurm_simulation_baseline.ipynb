{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd17711-8211-4a6c-a143-bfd23ca70ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import os \n",
    "import sys\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client\n",
    "from pathlib import Path\n",
    "\n",
    "import do_simulation_baseline as file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc39ade-9681-449d-bda2-588ad33554c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args setup\n",
    "ntrial = 50\n",
    "n = 500\n",
    "n_int = 100\n",
    "niter = 1000\n",
    "front_door = True\n",
    "minimise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af96fcf-2028-4154-af52-ca94c6de9876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/ghome/live/danceh/.local/mambaforge/envs/causalgp/lib/python3.12/site-packages/distributed/node.py:187: UserWarning: Port 11111 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 33399 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cluster creation\n",
    "cluster = SLURMCluster(\n",
    "    n_workers=0,\n",
    "    memory=\"32GB\",\n",
    "    processes=1,\n",
    "    cores=1,\n",
    "    scheduler_options={\n",
    "        \"dashboard_address\": \":11111\",\n",
    "        \"allowed_failures\": 10\n",
    "    },\n",
    "    job_cpu=1,\n",
    "    walltime=\"3:0:0\",\n",
    "    \n",
    "    job_extra_directives = [\"-p medium,fast,cpu\"],\n",
    ")\n",
    "cluster.adapt(minimum=0, maximum=200)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512e36b3-47b6-4200-bb66-ce2050429a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submitting jobs\n",
    "futures = []\n",
    "for seed in range(ntrial):\n",
    "        f = client.submit(file.main,\n",
    "                              seed,\n",
    "                              n,n_int,\n",
    "                              niter = niter,\n",
    "                              front_door = front_door,\n",
    "                              minimise = minimise\n",
    "                             )\n",
    "        futures += [f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5378f77d-7908-4cd5-990a-9e0f1888000f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: pending, key: main-1c02f02e7f6d446a0f5dbccd49ffcdd0>,\n",
       " <Future: pending, key: main-fc431fcbe84d08612c56cc8d34d03277>,\n",
       " <Future: pending, key: main-ac2b77c2f207f53d7a99448cfc039c8f>,\n",
       " <Future: pending, key: main-45bf24b81f49f1caac6fe2bf3f4697f0>,\n",
       " <Future: pending, key: main-a5da9861f5d0dfc695bdaa59c715cd3f>,\n",
       " <Future: pending, key: main-d754103a90352b1dd695c397b6409dc2>,\n",
       " <Future: pending, key: main-e1f2c0794babf1f25f1cc20ba1dc2dd5>,\n",
       " <Future: pending, key: main-057fd281dfd17be9ef5e9e393c31a11f>,\n",
       " <Future: pending, key: main-699bce4d1349e315eb1e6ccaa373d3ab>,\n",
       " <Future: pending, key: main-29eee1d48cce351145d568181a48795f>,\n",
       " <Future: pending, key: main-67ebd7800d8e6cb8cc55af25d24c4c0e>,\n",
       " <Future: pending, key: main-e68e64bdba0fefb71998cdf0a6608dea>,\n",
       " <Future: pending, key: main-1903148c8a5ae62d8813827a8732259f>,\n",
       " <Future: pending, key: main-0f218ba1534edc462abc027d8f1b582c>,\n",
       " <Future: pending, key: main-c724ed70a5475883bc47016dc1040a4f>,\n",
       " <Future: pending, key: main-666d073d7c32de61d54bcdb840c8c345>,\n",
       " <Future: pending, key: main-ce7b5d90485199857e8ec1bf6614c4b4>,\n",
       " <Future: pending, key: main-5cb3439de308b4eba0d76e808b9442ae>,\n",
       " <Future: pending, key: main-d5c88dc569840ec1a46e5321b5d0367e>,\n",
       " <Future: pending, key: main-23cc392919bff0d1f231016c36f7c25f>,\n",
       " <Future: pending, key: main-c67fbf3d4dd4d42ad74ea6da2e0c3961>,\n",
       " <Future: pending, key: main-a1f41d43cd66114798c5f1baa7b00df8>,\n",
       " <Future: pending, key: main-06cfb12f3382a0dc2f248be25f8a14ea>,\n",
       " <Future: pending, key: main-bd633ca35f15a8a7a2eff5d37fbefe1c>,\n",
       " <Future: pending, key: main-9b9d6db5611309813e716b77d08f2912>,\n",
       " <Future: pending, key: main-c219ca038a3902b6a8f27fa92bae4224>,\n",
       " <Future: pending, key: main-f25087993c05e6be45c95a51df0f9cd5>,\n",
       " <Future: pending, key: main-eeef31e098f912959dd721176d6ffff5>,\n",
       " <Future: pending, key: main-73bf8b66530505d3b6937edd7cd76058>,\n",
       " <Future: pending, key: main-6bc351ae40af04e45b968fa43055036d>,\n",
       " <Future: pending, key: main-6d02ded3d074b014a63f79b06dda4e44>,\n",
       " <Future: pending, key: main-4ce67ea6eedd31cce79f4a72cff4c0a3>,\n",
       " <Future: pending, key: main-6c12226e0401b099d7862a077d8c8edf>,\n",
       " <Future: pending, key: main-8005c860098227819ca84bc868f2febd>,\n",
       " <Future: pending, key: main-7891182ba119d67b8649251ed5bf28e1>,\n",
       " <Future: pending, key: main-f005b0f99b93f922c62d697e872a28fa>,\n",
       " <Future: pending, key: main-6722096cb0d98f3f29c298fcfc7ecf88>,\n",
       " <Future: pending, key: main-aa0c424665fc130a8897d7168353c3cc>,\n",
       " <Future: pending, key: main-94296c882386ed976e051e0908d6772f>,\n",
       " <Future: pending, key: main-6953e9d4cb0d7bdd4517bd0ccb63554b>,\n",
       " <Future: pending, key: main-5d6155167c8bb43a2398244178b71fc5>,\n",
       " <Future: pending, key: main-e4190f05863c6948660737adcf81cb39>,\n",
       " <Future: pending, key: main-d7b282e85220b0dbf2e1d84da5ceca4d>,\n",
       " <Future: pending, key: main-0c9029c1467b99646f4c3d9a2846266e>,\n",
       " <Future: pending, key: main-bf4bdfa674961d5e10676792bff8f1e8>,\n",
       " <Future: pending, key: main-768ab217a0adb06a6f4367c036ede971>,\n",
       " <Future: pending, key: main-5398c0507c18f1b6f132a605ca1074c5>,\n",
       " <Future: pending, key: main-7712d97334b44ce36751eb239d55c519>,\n",
       " <Future: pending, key: main-6d7c0135874d7b377cf6d69c1162b4ad>,\n",
       " <Future: pending, key: main-4b1756d0d8d43838577f4ebf8d943eb0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99fb39c7-f5c1-4d44-92df-b1a94309a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting results\n",
    "results = client.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa104ec-b8bc-406e-a690-ccc6a03a8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing client\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7eccd97-9915-4715-ae3c-23d065c72172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results\n",
    "torch.save(obj = results,\n",
    "           f = \"simulation_baseline_ntrial={0}_n={1}_frontdoor={2}_minimise={3}.pt\".format(ntrial,\n",
    "                                                                                             n,\n",
    "                                                                                             front_door,\n",
    "                                                                                             minimise)\n",
    "          )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
