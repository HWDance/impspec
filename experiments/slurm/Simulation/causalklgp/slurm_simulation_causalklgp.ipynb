{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd17711-8211-4a6c-a143-bfd23ca70ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import os \n",
    "import sys\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client\n",
    "from pathlib import Path\n",
    "\n",
    "import do_simulation_causalklgp as file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc39ade-9681-449d-bda2-588ad33554c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args setup\n",
    "ntrial = 50\n",
    "n = 100\n",
    "n_int = 100\n",
    "niter = 1000\n",
    "front_door = False\n",
    "minimise = True\n",
    "calibrate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af96fcf-2028-4154-af52-ca94c6de9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster creation\n",
    "cluster = SLURMCluster(\n",
    "    n_workers=0,\n",
    "    memory=\"32GB\",\n",
    "    processes=1,\n",
    "    cores=1,\n",
    "    scheduler_options={\n",
    "        \"dashboard_address\": \":11111\",\n",
    "        \"allowed_failures\": 10\n",
    "    },\n",
    "    job_cpu=1,\n",
    "    walltime=\"3:0:0\",\n",
    "    \n",
    "    job_extra_directives = [\"-p medium,fast,cpu\"],\n",
    ")\n",
    "cluster.adapt(minimum=0, maximum=200)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512e36b3-47b6-4200-bb66-ce2050429a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submitting jobs\n",
    "futures = []\n",
    "for seed in range(ntrial):\n",
    "        f = client.submit(file.main,\n",
    "                              seed,\n",
    "                              n,n_int,\n",
    "                              niter = niter,\n",
    "                              front_door = front_door,\n",
    "                              minimise = minimise,\n",
    "                              calibrate = calibrate\n",
    "                             )\n",
    "        futures += [f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8445a1bd-d2e2-4ed4-8f03-e2f3d035ad1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: pending, key: main-b6205cc7ebcd5124986cade05d607a33>,\n",
       " <Future: pending, key: main-75988b9b8ec5de585007a374c9eb5dfe>,\n",
       " <Future: pending, key: main-75f7e99692588296bf411e03108477f6>,\n",
       " <Future: pending, key: main-4ffc7c690ed455f9ebf034c8cb2dc43d>,\n",
       " <Future: pending, key: main-bd9e6559047897a58ae34f5dbfbf986e>,\n",
       " <Future: pending, key: main-40dad065979ba524faadb1095fdbf01b>,\n",
       " <Future: pending, key: main-e1ad4e2bb57001f00d7fe62fe5e07802>,\n",
       " <Future: pending, key: main-c419cf5dfc4655ded8cb42a727660462>,\n",
       " <Future: pending, key: main-287f0fbb7c4e322604ad45f4daa41087>,\n",
       " <Future: pending, key: main-f9f4018f888f4436970f62ea83ecb4ab>,\n",
       " <Future: pending, key: main-3183d6458221c21230267b789e876d6f>,\n",
       " <Future: pending, key: main-40d4084e11ff52126954cf0e7907ed34>,\n",
       " <Future: pending, key: main-2279d398e480754ecff66523cbb039ac>,\n",
       " <Future: pending, key: main-6aec3ee972057158ccb73a4f68356a54>,\n",
       " <Future: pending, key: main-6ee58111f61c81e1174031631945d097>,\n",
       " <Future: pending, key: main-0db9702f5e7fababa61013719e38507b>,\n",
       " <Future: pending, key: main-b265c0938a34ffdb03e9e6b15209bf12>,\n",
       " <Future: pending, key: main-690c59fc1ce2fbe7c788bee618571d2f>,\n",
       " <Future: pending, key: main-3b8604fda02cc57902dc8a67177c436d>,\n",
       " <Future: pending, key: main-9a115d2300de12375776e2983b1f6913>,\n",
       " <Future: pending, key: main-8f1190934a79dd80bcc4b6ef5a5ad159>,\n",
       " <Future: pending, key: main-501d7b69cbfd08b3323ac1e8380ad5ec>,\n",
       " <Future: pending, key: main-ad89213317644b6e280cf23f39c8baf5>,\n",
       " <Future: pending, key: main-cd32074c0c8678af8e14d531fbc0ea3c>,\n",
       " <Future: pending, key: main-68bbbf5129f7016f1997aa7f32718654>,\n",
       " <Future: pending, key: main-f3c3fa8e029152943b2e7031ae1564cd>,\n",
       " <Future: pending, key: main-fcc78a8a661a86e3767b366e0faf8cf8>,\n",
       " <Future: pending, key: main-fefa9fc09890ad655f7962fe2da7fedd>,\n",
       " <Future: pending, key: main-231bd22ae4123315ebd51a678edc0ed0>,\n",
       " <Future: pending, key: main-3ad38cc0d6b9c62e5f64fbc28b6ebef4>,\n",
       " <Future: pending, key: main-a0b58031782428f9934282737ce9dea4>,\n",
       " <Future: pending, key: main-1daa9a74e9995a389fbfa66a3c9ca1ba>,\n",
       " <Future: pending, key: main-f1601fa790141f497311c42894626194>,\n",
       " <Future: pending, key: main-04786245dcd960b442cbbf18a2dfcf6f>,\n",
       " <Future: pending, key: main-4fbab5ec7891f4bb32d612be3eec10eb>,\n",
       " <Future: pending, key: main-1756fc675b207c004098eea4bc3fdf13>,\n",
       " <Future: pending, key: main-109cf6b049b6034b2229d4eed33c9d8a>,\n",
       " <Future: pending, key: main-63616674f6facbba64e2b60da926b520>,\n",
       " <Future: pending, key: main-729f6de9908c816417a64041f4a9409b>,\n",
       " <Future: pending, key: main-e27d2567f978e0b03dc4a9aaad034adf>,\n",
       " <Future: pending, key: main-576b25a2e021a745732de8d293923041>,\n",
       " <Future: pending, key: main-1f46116220b7d1f55101251eb688f778>,\n",
       " <Future: pending, key: main-8b86d81334b10f83abe8b994454e246f>,\n",
       " <Future: pending, key: main-3c9235de70622a97b558de8c6bb03ecc>,\n",
       " <Future: pending, key: main-5424ae6000e8454883cc545beb0585d2>,\n",
       " <Future: pending, key: main-89179fd042c3e71eabb691ceded2e0f9>,\n",
       " <Future: pending, key: main-3789b4f38d86f021d41747c80c54ba89>,\n",
       " <Future: pending, key: main-6e3c85954a1ee73df02173f63750b3d2>,\n",
       " <Future: pending, key: main-c4a71a26995ad29b7cd80d4cd6977764>,\n",
       " <Future: pending, key: main-10ad011260a19b9708d1451dbfac6049>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5378f77d-7908-4cd5-990a-9e0f1888000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(futures)):\n",
    "    if futures[i].status == 'error':\n",
    "        futures[i] = futures[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99fb39c7-f5c1-4d44-92df-b1a94309a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting results\n",
    "results = client.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aa104ec-b8bc-406e-a690-ccc6a03a8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing client\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7eccd97-9915-4715-ae3c-23d065c72172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results\n",
    "torch.save(obj = results,\n",
    "           f = \"simulation_causalklgp_ntrial={0}_n={1}_frontdoor={2}_minimise={3}.pt\".format(ntrial,\n",
    "                                                                                             n,\n",
    "                                                                                             front_door,\n",
    "                                                                                             minimise)\n",
    "          )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
