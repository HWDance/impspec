{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46268684-f281-4b9c-90f1-392537f18dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import os \n",
    "import sys\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client\n",
    "from pathlib import Path\n",
    "\n",
    "import do_ablation_baselinegp as file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c24b2e-ac59-421b-ac72-e790d04a8471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args setup\n",
    "ntrial = 50\n",
    "n = 100\n",
    "ntest = 100\n",
    "d = 5\n",
    "noise = 0.5\n",
    "niter = 1000\n",
    "error_samples = 100\n",
    "gp_samples = 1000\n",
    "kernel = \"gaussian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb863671-3c55-4e69-9537-cf846582a6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/ghome/live/danceh/.local/mambaforge/envs/causalgp/lib/python3.12/site-packages/distributed/node.py:187: UserWarning: Port 11111 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 39863 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cluster creation\n",
    "cluster = SLURMCluster(\n",
    "    n_workers=0,\n",
    "    memory=\"32GB\",\n",
    "    processes=1,\n",
    "    cores=1,\n",
    "    scheduler_options={\n",
    "        \"dashboard_address\": \":11111\",\n",
    "        \"allowed_failures\": 10\n",
    "    },\n",
    "    job_cpu=1,\n",
    "    walltime=\"3:0:0\",\n",
    "    job_extra_directives = [\"-p medium,fast,cpu\"],\n",
    ")\n",
    "cluster.adapt(minimum=0, maximum=200)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c50cdf79-4a43-4cdc-8918-e82792b554b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submitting jobs\n",
    "futures = []\n",
    "for seed in range(ntrial):\n",
    "            f = client.submit(file.main,seed,n,ntest,d,noise,\n",
    "                             error_samples = error_samples, gp_samples = gp_samples,\n",
    "                             niter = niter, kernel = kernel)\n",
    "            futures += [f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a248d795-5e4d-4ac4-8a21-5f84775f9ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: pending, key: main-fd177b85f11ecebceb044a512caf2808>,\n",
       " <Future: pending, key: main-dabac6dc6d8b7e2d4523e2d68733f66f>,\n",
       " <Future: pending, key: main-5588a1c18fbce0828982c4a20f2c9190>,\n",
       " <Future: pending, key: main-f532fb7d8e73d1a24f9ef61817733760>,\n",
       " <Future: pending, key: main-e2504ebbfc044047c42dc866c5bdcbd3>,\n",
       " <Future: pending, key: main-29b0de156d4c09a57a93e495abd55968>,\n",
       " <Future: pending, key: main-98f118e91a976013f0fdf0caaab3192f>,\n",
       " <Future: pending, key: main-f6b9298249bc8d6ec212884cf0572889>,\n",
       " <Future: pending, key: main-ad6af75675b718b206abb574d9afc819>,\n",
       " <Future: pending, key: main-d2e837d18d653310a54fba791632bfef>,\n",
       " <Future: pending, key: main-6e2c283b8eca1820c0084c51374a9928>,\n",
       " <Future: pending, key: main-96753bf3c34f1af6c1dc2e3fd03b8843>,\n",
       " <Future: pending, key: main-dd3e5af737172399b1f19702ec972a8f>,\n",
       " <Future: pending, key: main-46d9d8302f53fc660ddeff588e903196>,\n",
       " <Future: pending, key: main-5e83aa2fd4d6056bff6193b294bbcdd4>,\n",
       " <Future: pending, key: main-418e590af913db5c6dc0d0081df7e57f>,\n",
       " <Future: pending, key: main-65bfe1f7016992412f0414b0d73d9365>,\n",
       " <Future: pending, key: main-bfbb3c60f744f51ab0a9ed030d50dc24>,\n",
       " <Future: pending, key: main-9e57982b4594248fe4f82992e5d19be6>,\n",
       " <Future: pending, key: main-76e2780544f4beaf5de4d6264808201e>,\n",
       " <Future: pending, key: main-35df660ef93cfd6e740a84cd62d9a9f6>,\n",
       " <Future: pending, key: main-0cab48f278ba76a39b2ddde2674b0ae9>,\n",
       " <Future: pending, key: main-e70d607be4c35d1b1d5ba93773ba96a4>,\n",
       " <Future: pending, key: main-c6ad54d592eaf4c1570f81d9ef34c28c>,\n",
       " <Future: pending, key: main-94d4fcd10a0d2513dc3d3087c7bb5178>,\n",
       " <Future: pending, key: main-5468e3c3db3f58750310e90d057e0390>,\n",
       " <Future: pending, key: main-b5106c84a58fd5edcc0ecb22c3af61eb>,\n",
       " <Future: pending, key: main-45e22f2d7df35bd13fd47ae6e15a7360>,\n",
       " <Future: pending, key: main-d33ecad68ea577e5ef03a63cbaffbb4e>,\n",
       " <Future: pending, key: main-51276d804a27b9cdf87fa85d198019f8>,\n",
       " <Future: pending, key: main-43a00360aa12b116f576c368461b300d>,\n",
       " <Future: pending, key: main-347002095bcfb8534ac06538e5fdc822>,\n",
       " <Future: pending, key: main-63dcb31187156201e6b8fc51935e0c9e>,\n",
       " <Future: pending, key: main-e688a13f73926db993e2d397e407527e>,\n",
       " <Future: pending, key: main-1836fa6599a640eadfc480749bd96bba>,\n",
       " <Future: pending, key: main-5dbeeeb84c44a4b7240cd79258cdf8ae>,\n",
       " <Future: pending, key: main-7e0a8e1daae19510dfa1ab3a85fa635b>,\n",
       " <Future: pending, key: main-3aabac3b1e0d8b39f4675b635884a59d>,\n",
       " <Future: pending, key: main-6e46b6925f813a83088d568a1b445fa8>,\n",
       " <Future: pending, key: main-8ebf15e3317efeb53896fde7c126c01c>,\n",
       " <Future: pending, key: main-15e92337d14abe52c582e528e647feb4>,\n",
       " <Future: pending, key: main-6def15c5a89080c36a77585815233a76>,\n",
       " <Future: pending, key: main-5b9a6eff9d5139cb1a3550fbe2e3164b>,\n",
       " <Future: pending, key: main-8adda095df3d62eac4034525c8322eec>,\n",
       " <Future: pending, key: main-21b0c914c591555cf7b996825176f5d1>,\n",
       " <Future: pending, key: main-5bd559e0bf2cf113324e6d42d51764dc>,\n",
       " <Future: pending, key: main-9b8b1438721e0db6024199db674ce64e>,\n",
       " <Future: pending, key: main-d658e7f8b7babcf72874fd3435993f35>,\n",
       " <Future: pending, key: main-a6540dde6730a2c0f9e0afee30b54c7a>,\n",
       " <Future: pending, key: main-074b527db45957a282d8ffa524d36614>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check on futures\n",
    "futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f18c8218-4374-4884-83fa-f4a28f8cbbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting results\n",
    "results = client.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "555c9e87-bb97-4c84-83ef-ba7d92cb0b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing client\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a3ac498-c027-4afe-8149-cf049bc4a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results\n",
    "torch.save(obj = results,\n",
    "           f = \"ablation_baselinegp_ntrial={0}_n={1}_d={2}_noise={3}_kernel={4}.pt\".format(ntrial,n,d,noise,kernel))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
